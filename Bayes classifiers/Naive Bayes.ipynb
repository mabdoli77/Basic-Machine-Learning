{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Naive Bayes classifier on the iris dataset from <a href=\"https://archive.ics.uci.edu/ml/datasets/iris\">UCI Repository</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "df = pd.read_csv(\"...\\\\iris.csv\")\n",
    "df =  shuffle(df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_prior(train_set):\n",
    "    split_by_class = train_set.groupby('iris')\n",
    "    prior_dic = {}\n",
    "    for class_name, split_data in split_by_class:\n",
    "        prior_dic[class_name] = len(split_data)/len(train_set)\n",
    "    return prior_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(train_set, feature_name):\n",
    "    conditional_split_data = train_set.groupby('iris')[feature_name].value_counts()\n",
    "    conditional_split_dic = conditional_split_data.to_dict()\n",
    "    conditional_split_probs = {}\n",
    "    #calculate the probability of each class based on condition: variable == feature_name\n",
    "    for i in conditional_split_dic.keys(): \n",
    "        conditional_split_probs[i] = conditional_split_dic[i]/len(train_set)\n",
    "    return conditional_split_probs, conditional_split_dic #returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplyList(myList) :  \n",
    "    result = 1\n",
    "    for x in myList: \n",
    "         result = result * x  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(train_Set, test_Set):\n",
    "    import numpy as np\n",
    "    import operator\n",
    "    predicted = []\n",
    "    prior_dict = calculate_class_prior(train_Set)\n",
    "    numpy_data = test_Set.values\n",
    "    for x in np.nditer(numpy_data, flags = ['external_loop'], op_flags = ['readwrite'] ,order = 'C'):\n",
    "        posterior = {}\n",
    "#         print(x)\n",
    "        for i in range(1, 4):   #itertate over classes\n",
    "#             print(i)\n",
    "            probs = []\n",
    "            for j in range(4):\n",
    "                feature_name = test_Set.columns[j]\n",
    "                feature_value = x[j]\n",
    "                dict_tuple = (i, feature_value) ## a tuple ==> (class,number of samples in the feature with class i)\n",
    "#                 print(dict_tuple)\n",
    "                likelihood_dict, _ = likelihood(train_Set, feature_name)\n",
    "                if dict_tuple in likelihood_dict.keys():\n",
    "                    probs.append(likelihood_dict[dict_tuple])\n",
    "                else:\n",
    "                    probs.append(0)\n",
    "\n",
    "#             print(probs)\n",
    "#             print(multiplyList(probs))\n",
    "            posterior[i] = multiplyList(probs) * prior_dict[i] #multiply prior and likelihood to get posetrior\n",
    "\n",
    "#         print(posterior)\n",
    "        argmax = max(posterior, key=posterior.get)\n",
    "#         print(\"CLASSS IS: \", argmax)\n",
    "        predicted.append(argmax)\n",
    "    actual_labels = numpy_data[:, -1:]\n",
    "    actual_labels = np.reshape(actual_labels, (1,-1))\n",
    "    return predicted, actual_labels.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = df.iloc[105:, :]\n",
    "# train_data = df.iloc[:105, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(dataframe, split_ratio=0.7):\n",
    "    index = round(len(dataframe) * split_ratio)\n",
    "    train_data = dataframe.iloc[:index, :]\n",
    "    test_data = dataframe.iloc[index:, :]\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_of_algorithm, actual  = prediction(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.333333333333336"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(actual[0],predictions_of_algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "low accuracy is an indication that Naive Bayes classifier is not an ideal candidate for non-categorical variables as the probability of zero frequency problem increases in non-categorical datasets. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
