{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes classifier with smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An implementation of Naive Bayes classifier with smoothing to solve the zero frequency problem. <br>\n",
    "The classifier is applied on the iris data set from the <a href=\"https://archive.ics.uci.edu/ml/datasets/iris\">UCI Repository</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping data points with respect to their classes to calculate the prior possibilities for each class. \n",
    "def calculate_class_prior(train_set):\n",
    "    split_by_class = train_set.groupby('iris')\n",
    "    prior_dic = {}\n",
    "    for class_name, split_data in split_by_class:\n",
    "        prior_dic[class_name] = len(split_data)/len(train_set)\n",
    "    return prior_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(train_set, feature_name):\n",
    "    conditional_split_data = train_set.groupby('iris')[feature_name].value_counts()\n",
    "    conditional_split_dic = conditional_split_data.to_dict()\n",
    "    return  conditional_split_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_with_smoothing(spit_dictionary):\n",
    "\n",
    "    conditional_split_probs = {}\n",
    "    for i in spit_dictionary.keys():\n",
    "        k = spit_dictionary[i]\n",
    "        conditional_split_probs[i] = spit_dictionary[i] + (4 * (1/k)) /105 + 4  ## smoothing possibilities, 4 is the number \n",
    "                                                                                ## of features, (1/k) is 1/number of classes\n",
    "    return conditional_split_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplyList(myList) : \n",
    "      \n",
    "    # Multiply elements one by one \n",
    "    result = 1\n",
    "    for x in myList: \n",
    "         result = result * x  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(train_Set, test_Set):\n",
    "    import numpy as np\n",
    "    import operator\n",
    "    predicted = []\n",
    "    prior_dict = calculate_class_prior(train_Set)\n",
    "    numpy_data = test_Set.values\n",
    "    for x in np.nditer(numpy_data, flags = ['external_loop'], op_flags = ['readwrite'] ,order = 'C'):\n",
    "        posterior = {}\n",
    "#         print(x)\n",
    "        for i in range(1, 4):   #itertate over classes\n",
    "#             print(i)\n",
    "            probs = []\n",
    "            for j in range(4):\n",
    "                feature_name = test_Set.columns[j]\n",
    "                feature_value = x[j]\n",
    "                dict_tuple = (i, feature_value)\n",
    "#                 print(dict_tuple)\n",
    "                likelihood_dic_for_smooth = likelihood(train_Set, feature_name)\n",
    "                likelihood_dict = likelihood_with_smoothing(likelihood_dic_for_smooth)\n",
    "                if dict_tuple in likelihood_dict.keys():\n",
    "                    probs.append(likelihood_dict[dict_tuple])\n",
    "                else:\n",
    "                    probs.append(0)\n",
    "\n",
    "#             print(probs)\n",
    "#             print(multiplyList(probs))\n",
    "            posterior[i] = multiplyList(probs) * prior_dict[i]\n",
    "\n",
    "#         print(posterior)\n",
    "        argmax = max(posterior, key=posterior.get)\n",
    "#         print(\"CLASSS IS: \", argmax)\n",
    "        predicted.append(argmax)\n",
    "    actual_labels = numpy_data[:, -1:]\n",
    "    actual_labels = np.reshape(actual_labels, (1,-1))\n",
    "    return predicted, actual_labels.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(dataframe, split_ratio=0.7):\n",
    "    index = round(len(dataframe) * split_ratio)\n",
    "    train_data = dataframe.iloc[:index, :]\n",
    "    test_data = dataframe.iloc[index:, :]\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = pd.read_csv(\"...\\\\iris.csv\")\n",
    "    df =  shuffle(df, random_state=55)\n",
    "    train_data, test_data = split_train_test(df)\n",
    "    predictions_of_algorithm, actual  = prediction(train_data, test_data)\n",
    "    accuracy = calculate_accuracy(actual[0],predictions_of_algorithm)\n",
    "    print('accuracy of algorithm is: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of algorithm is:  73.33333333333333\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using smoothing process is a solution to zero frequency problem in Naive Bayes process. zero frequency problem occures when the categorical variable is not observed in the training set.  <br>\n",
    "Smoothing increases Accuracy measure in comparison to previous implementation of Naive Bayes algorithm on the same dataset, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
